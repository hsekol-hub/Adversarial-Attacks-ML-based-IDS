# Adversarial Attacks on ML-based Intrusion Detection Systems
This is the official code release of the following paper: 

TBA

<img src="https://github.com/hsekol-hub/Adversarial-Attacks-ML-based-IDS/blob/main/config/tmp/pipeline.png" alt="pipeline" width="700" class="center">

## Quick Start

### Environment variables & installations
First, clone repository
Install virtualenv
```
pip install virtualenv

virtualenv -p python3.7 venv

source venv/bin/activate
```
### Install dependencies
```
pip install -r requirement.txt
```

### Process data
First, unzip and unpack the data files 


### Train models
Then the following commands can be used to train the proposed models. By default, dev set evaluation results will be printed when training terminates.


### Evaluate models


### Change the hyperparameters
To get the optimal result reported in the paper, change the hyperparameters and other experiment set up according to Section 5.1.4 in the paper  


## Citation
If you find the resource in this repository helpful, please cite